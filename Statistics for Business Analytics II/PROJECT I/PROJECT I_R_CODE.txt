############# P28220003 - PROJECT I - STATISTICS - MSc IN BUSINESS ANALYTICS ################################################

dictionary<- read.csv(file.choose(),header = T, sep = ";") # load the dictionary file 
county_facts<- read.csv(file.choose(),header = T, sep = ";") # load the county_facts file
votes<- read.csv(file.choose(),header = T, sep = ";") # load the votes file 

library(DataExplorer)
library(tidyverse)
library(dplyr)
library(tidyr)
library(summarytools)

# filter only the Democrat votes 
votes <- filter(votes, party %in% c("Democrat"))

#create dictionary2 with State mapping 

dictionary2 <- as.data.frame(cbind(votes$state_abbreviation, votes$state))
colnames(dictionary2)[colnames(dictionary2)=="V1"] <- "state_abbreviation"
colnames(dictionary2)[colnames(dictionary2)=="V2"] <- "state"
dictionary2 <- distinct(dictionary2, state_abbreviation, .keep_all = TRUE)
dictionary2$fips <- county_facts$fips[match(dictionary2$state,county_facts$area_name)]
dictionary2<- dictionary2 %>% relocate(fips, .before = state_abbreviation)

# first look of the data 
introduce(county_facts)
introduce(votes)

# find missing values 
na_values <- which(colSums(is.na(votes)) > 0)
sort(colSums(sapply(votes[na_values], is.na)), decreasing = TRUE) #fips 20 missing values - New Hampshire State

# create reference table 
subset1<- subset(county_facts,county_facts$state_abbreviation=="NH")[1:3]
subset1<- separate(subset1, col = area_name, into = c("Value1","Value2"), sep = " ") # ok 

# impute the missing values 
votes$fips[is.na(votes$fips)] <- subset1$fips[match(votes$county,subset1$Value1)][which(is.na(votes$fips))]
which(colSums(is.na(votes)) > 0) # 0 NAs

# create pivot by county in order to create response by county  

pivot<- votes
pivot<- pivot %>%
  select(fips, candidate, votes ) %>%
  group_by(fips,candidate) %>%
  summarise(Total_Votes = sum(votes))

pivot <- pivot %>% 
  spread(candidate, Total_Votes)

pivot <- as.data.frame(pivot)

summary(pivot) # NAs 

pivot<- pivot %>% replace_na(list(` No Preference` = 0, ` Uncommitted` = 0, `Martin O'Malley` = 0))

str(pivot)
summary(pivot) # 4205 rows 

# check the draw result
filter(pivot, `Bernie Sanders` == `Hillary Clinton`)           # 166 rows - 79 draw not zero 
filter(pivot, `Bernie Sanders` == 0 & `Hillary Clinton` == 0)  # 87 rows - everything zero - wrong response 

pivot <- filter(pivot, `Bernie Sanders` != 0 | `Hillary Clinton` != 0) # reverse 

# create response variable based on who whas the most votes - "winner takes all" game 
pivot$Response <- ifelse(pivot$`Hillary Clinton` > pivot$`Bernie Sanders`, 1, 0)

# create Total Votes 
pivot$TOTAL_ALL <- rowSums(pivot[2:6]) # total based in  all candidates
pivot$TOTAL_HCBS <- rowSums(pivot[4:5])   # total for HC  & BS

# keep only Bernie Sanders and Hillary Clinton
pivot <- select(pivot, -c(` No Preference`, ` Uncommitted`, `Martin O'Malley`  ))

# repeat the same procedure for creating response by state 
pivot1<- votes
pivot1<-  pivot1 %>%
  select(state_abbreviation, candidate, votes ) %>%
  group_by(state_abbreviation,candidate) %>%
  summarise(Total_Votes = sum(votes))
pivot1 <- pivot1 %>% 
  spread(candidate, Total_Votes)
pivot1 <- as.data.frame(pivot1)
pivot1<- pivot1 %>% replace_na(list(` No Preference` = 0, ` Uncommitted` = 0, `Martin O'Malley` = 0))
pivot1$Response <- ifelse(pivot1$`Hillary Clinton` > pivot1$`Bernie Sanders`, 1, 0)
pivot1 <- select(pivot1, -c(` No Preference`, ` Uncommitted`, `Martin O'Malley`  ))

# merge data 
data<- merge.data.frame(county_facts,pivot, by = "fips")

data<- data %>% relocate(`Bernie Sanders`, .before = PST045214)
data<- data %>% relocate(`Hillary Clinton`, .before = PST045214)
data<- data %>% relocate(TOTAL_ALL, .before = PST045214)
data<- data %>% relocate(TOTAL_HCBS, .before = PST045214)
data<- data %>% relocate(Response, .before = PST045214)
colnames(data)[colnames(data)=="area_name"] <- "County"
data<- data %>% relocate(state_abbreviation, .before = County)
View(data)

# deal  with  non zero tie results  
problems_tie<- filter(data, `Bernie Sanders` == `Hillary Clinton`) 
problems_tie<- select(problems_tie, -c(-fips,-state_abbreviation,-Response))
problems_tie$Response_OK <- pivot1$Response[match(problems_tie$state_abbreviation,pivot1$state_abbreviation)]
problems_tie <- select(problems_tie, c(fips, state_abbreviation, Response_OK))
View(problems_tie)

change <- problems_tie$fips[which(problems_tie$Response_OK == 1)]
data$Response[which(data$fips %in% change)] <- 1  

data$state_abbreviation <- as.factor()

# change commas to dots and convert into numeric  
data[,-c(2,3)]<- sapply(data[,-c(2,3)], function(x) as.numeric(gsub(",",".",x)))

# check for  missing values 
na_values1 <- which(colSums(is.na(data)) > 0)
sort(colSums(sapply(data[na_values1], is.na)), decreasing = TRUE) # no missing values in data

# add State column 
data$State <- NA 
data<- data %>% relocate(State, .before = County)
data$State[is.na(data$State)] <- dictionary2$state[match(data$state_abbreviation,dictionary2$state_abbreviation)][which(is.na(data$State))]

# find missing values 
na_values2 <- which(colSums(is.na(data)) > 0)
sort(colSums(sapply(data[na_values2], is.na)), decreasing = TRUE) 

data$state_abbreviation <- as.factor(data$state_abbreviation)
data$Response <- as.numeric(data$Response)

class(data)
mode(data)
str(data)


# write.csv(data, "finaldata")  #  use it in the correlation matrix  and model building section


############################################################################################################################
#              CORRELATION MATRIX - work with finaldata file 
################################################################################################################################

finaldata<- read.csv(file.choose(), header = T, sep = ",")
finaldata<- finaldata[,-1]

library(dplyr)
library(Hmisc)
library(corrplot) 

data_cor<- finaldata[,-c(1:8)]
data_cor$Response <- as.numeric(data_cor$Response)

corr1 <- cor(data_cor, use="pairwise.complete.obs") # Pearson correlations of all numeric variables

corr1_sorted <- as.matrix(sort(corr1[,'Response'], decreasing = TRUE)) # sort correlations - Response at top

CorHigh <- names(which(apply(corr1_sorted, 1, function(x) abs(x)>0.25 ))) #select only high correlations with Response 
corr1 <- corr1[CorHigh, CorHigh] 

par(mfrow=c(1,1))
corrplot.mixed(corr1, tl.col="black", tl.pos = "lt")




# flattenCorrMatrix function - for seeing correlations
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
  )
}


corr_num1<- rcorr(as.matrix(data_cor)) # # CORRELATION matrix for all pairs
correlation1<- flattenCorrMatrix(corr_num1$r, corr_num1$P) # will be used later on

# 0.42 Black or African American alone, percent, 2014
# 0.26 Black-owned firms, percent, 2007


# -0.38 White alone, not Hispanic or Latino, percent, 2014
# -0.34 White alone, percent, 2014
# -0.34 High school graduate or higher, percent of persons age 25+, 2009-2013


############################################################################################################################
# EXPLORATORY DATA ANALYSIS SECTION 
############################################################################################################################

finaldata$Response <- as.factor(finaldata$Response) # factor for visualization purposes 

library(ggplot2)
library(gridExtra)

# Total Votes by State -     Create a grouped bar graph 

# Total Votes by State -     Create a stacked grouped bar graph 
p1<-ggplot(finaldata, aes(x=state_abbreviation, y=TOTAL_HCBS, fill=Response)) + 
  geom_bar(stat="identity", position="stack") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_fill_discrete(name = "Candidate", labels = c("Bernie Sanders", "Hillary Clinton")) + ggtitle("Total Votes by State")

p1


p2<-ggplot(data=finaldata, aes(x=reorder(state_abbreviation, INC110213, FUN=mean), y=INC110213)) +
  geom_bar(position = "stack", stat = "summary",,fill="steelblue")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_y_continuous(breaks= seq(0, 122000, by=10000), labels = scales::comma)+
  geom_hline(yintercept = mean(finaldata$INC110213), linetype="dashed", color="red") + xlab("State") +
  ggtitle("Median Income by State")

p2



p3 <- ggplot(finaldata, aes(x = factor(Response), y = RHI125214)) +
  geom_boxplot(outlier.size = 1.5, outlier.shape = 21,col='black',fill="grey") +
  scale_x_discrete(name = "Candidate", labels = c("Bernie Sanders", "Hillary Clinton"))+
  ylab("White alone, percent, 2014") + ggtitle("White alone, percent, 2014 by Candidate")

p3

p32<- ggplot(finaldata, aes(x = factor(Response), y = RHI225214)) +
  geom_boxplot(outlier.size = 1.5, outlier.shape = 21,col='black',fill="grey") +
  scale_x_discrete(name = "Candidate", labels = c("Bernie Sanders", "Hillary Clinton"))+
  ylab("Black alone, percent, 2014") + ggtitle("Black alone, percent, 2014 by Candidate")

p32

grid.arrange(p3,p32, ncol=2)



p5 <- ggplot(finaldata, aes(x=factor(Response), y=SEX255214)) + 
  geom_boxplot(outlier.size = 1.5, outlier.shape = 21, col="ivory1",fill="honeydew4") + 
  scale_x_discrete(name = "Candidate", labels = c("Bernie Sanders", "Hillary Clinton"))+
  ylab("Female persons, percent") + ggtitle("Female persons, percent")

p6 <- ggplot(finaldata, aes(x=factor(Response), y=SBO015207)) + 
  geom_boxplot(outlier.size = 1.5, outlier.shape = 21, col="ivory1",fill="honeydew4") + 
  scale_x_discrete(name = "Candidate", labels = c("Bernie Sanders", "Hillary Clinton"))+
  ylab("Women-owned firms, percent") + ggtitle("Women-owned firms, percent")

grid.arrange(p5,p6, ncol=2)



par(mfrow=c(1,3))
hist(finaldata$AGE135214, main="Persons under 5 years",  xlab="Percent", border="blue", col="azure4")
hist(finaldata$AGE295214, main="Persons under 18 years",  xlab="Percent", border="blue", col="azure4")
hist(finaldata$AGE775214, main="Persons 65 years and over",  xlab="Percent", border="blue", col="azure4")

library(nortest)
lillie.test(finaldata$AGE135214) # no normality
lillie.test(finaldata$AGE295214) # no normality
lillie.test(finaldata$AGE775214) # no normality

######################################################################################################################################################
#  GLM - MODEL BUILDING SECTION - work with final data and lasso_data file 
######################################################################################################################################################

finaldata<- read.csv(file.choose(), header = T, sep = ",") # load the finaldata file 
finaldata<- finaldata[,-1] # remove X column

data1<- finaldata[,-c(1:8)] # df for the lasso 
require(glmnet)
X <- model.matrix(Response~., data1 )[,-data1$Response]
lasso <- glmnet(X, data1$Response,alpha = 1, family = "binomial")
plot(lasso, xvar = "lambda", label = T)

lasso1 <- cv.glmnet(X, data1$Response, alpha = 1, family = "binomial", type.measure = "class")
plot(lasso1)

plot(lasso1$glmnet.fit, xvar = "lambda")
abline(v=log(c(lasso1$lambda.min, lasso1$lambda.1se)), lty =2)
c<-coef(lasso1,s='lambda.1se',exact=TRUE)
inds<-which(c!=0)
variables<-row.names(c)[inds]
variables<-variables[variables %nin% '(Intercept)']
variables # lasso selected variables
length(variables)
lasso1$lambda.min # 0.0002597274
lasso1$lambda.1se # 0.006141228 # optimal lambda 


# lasso_data <- data1[,variables[-1]]
# lasso_data$Response <- data1$Response
# lasso_data<- lasso_data %>% relocate(Response, .before = PST120214)
# write.csv(lasso_data, "lasso_data") # lasso selected variables 

lasso_data<- read.csv(file.choose(),header = T, sep = ",") # load the lasso_data file 
lasso_data<- lasso_data[-1] # remove the X column 


model1 <- glm(Response~., data=lasso_data, family = binomial())  # model1 with lasso selected variables 
summary(model1) 

model2 <- glm(Response~. -RHI325214 -VET605213 -BZA115213 -SBO215207 -LND110210,
              data = lasso_data, family = binomial()) # exclude the statistically non significant values 


model2$coefficients
summary(model2) # ok 

# likelihood ratio test 

with(model2, null.deviance - deviance) # 1514.518

with(model2, df.null - df.residual) # 14 

with(model2, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) # p-value 3.533542e-315

# we can assume from the above three commands that the 
# chi-square of 1514.518 with 14 degrees of freedom and an associated p-value of less than 0.005 
# tells us that our model as a whole fits significantly better than the null model.

# exponentiate the coefficients and interpret them as odds-ratios
exp(coef(model2))
exp(cbind(OR = coef(model2), confint(model2)))

# pseudoR2 
library(pscl)
pR2(model2)


###############################################################################################################################

aic_model <- step(model2, direction = "both")

summary(aic_model)   # same model with model2 - no improvement 

###############################################################################################################################

bic_model <- step(model2, direction='both',k=log(length(lasso_data$Response))) # bic_model with BIC stepwise variable selection

summary(bic_model) # summary of bic_model

# likelihood ratio test 

with(bic_model, null.deviance - deviance) # 1503.126

with(bic_model, df.null - df.residual) # 12 

with(bic_model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE)) # p-value 8.015522e-315

# we can assume from the above three commands that the 
# chi-square of 1514.518 with 14 degrees of freedom and an associated p-value of less than 0.005 
# tells us that our model as a whole fits significantly better than the null model.

vif(bic_model) # check for multicollinearity 

# exponentiate the coefficients and interpret them as odds-ratios
exp(coef(bic_model))
exp(cbind(OR = coef(bic_model), confint(bic_model)))

pR2(bic_model)

anova(bic_model, model2, test = "LR") # for comparison between the two using Likelihood Ratio Tests  


