{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######  SPARK ASSIGNMENT - P2822003 - VRETTEAS STYLIANOS ######\n",
    "\n",
    "## PREPARATION  \n",
    "\n",
    "# load basic packages\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F \n",
    "# from pyspark.sql import Window\n",
    "\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "spark =  SparkSession.builder.appName(\"test\").getOrCreate()\n",
    "spark\n",
    "\n",
    "#load data\n",
    "flights_data = spark.read\\\n",
    "                    .option(\"header\",\"true\")\\\n",
    "                    .option(\"inferSchema\",\"true\")\\\n",
    "                    .csv(\"671009038_T_ONTIME_REPORTING.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count flights_data last check\n",
    "n1 = flights_data.count()\n",
    "print(\"number of rows all data:\", n1)\n",
    "n2 = flights_data.dropDuplicates().count()\n",
    "print(\"number of rows after deleting duplicates:\", n2)\n",
    "n3 = n1 - n2 \n",
    "print(\"duplicate_data:\", n3)\n",
    "\n",
    "# drop duplicates \n",
    "flights_data = flights_data.dropDuplicates()\n",
    "print(\"number of rows final:\", flights_data.count())\n",
    "\n",
    "\n",
    "# display details about the dataframe \n",
    "display(flights_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TASK 2 \n",
    "\n",
    "\n",
    "# create df2 \n",
    "df2 =flights_data.select(\"FL_DATE\",\"TAIL_NUM\",\"ORIGIN\",\"CARRIER\",\"DEP_DELAY\",\"DEST\")\n",
    "df2.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicated rows \n",
    "\n",
    "# count Rows and Duplicate rows\n",
    "n1 = df2.count()\n",
    "print(\"number of rows df2:\", n1)\n",
    "n2 = df2.dropDuplicates().count()\n",
    "print(\"number of rows after deleting duplicates:\", n2)\n",
    "n3 = n1 - n2 \n",
    "print(\"duplicate_data:\", n3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates \n",
    "\n",
    "df2 = df2.dropDuplicates()\n",
    "#print (\"number of rows:\", df2.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check outliers\n",
    "\n",
    "df_outliers = df2.select(\"ORIGIN\")\n",
    "\n",
    "df_outliers_group = df_outliers.groupBy(\"ORIGIN\").count()\n",
    "\n",
    "df_outliers_group.orderBy(\"count\", ascending = True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK OUTLIERS in the number of flights \n",
    "outliers = df_outliers_group.approxQuantile(\"count\", [0.01], 0.0)\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows 99%\n",
    "df2.filter(~F.col(\"ORIGIN\").isin([\"AKN\",\"PGV\",\"GST\",\"DLG\"])).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows 1%\n",
    "df2.filter(F.col(\"ORIGIN\").isin([\"AKN\",\"PGV\",\"GST\",\"DLG\"])).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter df2 ( remove the outliers)\n",
    "df2 = df2.filter(~F.col(\"ORIGIN\").isin([\"AKN\",\"PGV\",\"GST\",\"DLG\"]))\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY ORIGIN - AVG_DEP_DELAY - OK\n",
    "BY_ORIGIN_AVG = df2.groupBy(\"ORIGIN\").agg(F.expr(\"avg(DEP_DELAY)\").alias(\"AVG_DEP_DELAY\"))\n",
    "\n",
    "BY_ORIGIN_AVG.orderBy(\"AVG_DEP_DELAY\", ascending = False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIAN FUNCTION \n",
    "median_percentile = F.expr('percentile_approx(DEP_DELAY, 0.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY ORIGIN - MEDIAN - OK\n",
    "BY_ORIGIN_MED = df2.groupBy(\"ORIGIN\").agg(median_percentile.alias(\"MED_DEP_DELAY\"))\n",
    "\n",
    "BY_ORIGIN_MED.orderBy(\"MED_DEP_DELAY\", ascending = False).show()\n",
    "\n",
    "#  median_percentile = F.expr('percentile_approx(DEP_DELAY, 0.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY CARRIER - AVG_DEP_DELAY (DRAFT) - 17 rows - OK \n",
    "BY_CARRIER_AVG = df2.groupBy(\"CARRIER\").agg(F.expr(\"avg(DEP_DELAY)\").alias(\"AVG_DEP_DELAY\"))\n",
    "\n",
    "BY_CARRIER_AVG.orderBy(\"AVG_DEP_DELAY\", ascending = False).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY CARRIER - MED_DEP_DELAY (DRAFT) - 17 rows - OK \n",
    "BY_CARRIER_MED = df2.groupBy(\"CARRIER\").agg(median_percentile.alias(\"MED_DEP_DELAY\"))\n",
    "\n",
    "BY_CARRIER_MED.orderBy(\"MED_DEP_DELAY\", ascending = False).show()\n",
    "\n",
    "# median_percentile = F.expr('percentile_approx(DEP_DELAY, 0.5)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY_ORIGIN_AVG 100 first rows \n",
    "\n",
    "task2_ap_avg = BY_ORIGIN_AVG.limit(100)\n",
    "task2_ap_avg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY_ORIGIN_MED 100 first rows\n",
    "\n",
    "task2_ap_med = BY_ORIGIN_MED.limit(100)\n",
    "task2_ap_med.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY_CARRIER_AVG 100 first rows \n",
    "task2_aw_avg = BY_CARRIER_AVG.limit(100)\n",
    "task2_aw_avg.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BY_CARRIER_MED 100 first rows\n",
    "task2_aw_med = BY_CARRIER_MED.limit(100)\n",
    "task2_aw_med.count()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv task2_ap_avg\n",
    "task2_ap_avg.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-ap-avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv task2_ap_med\n",
    "task2_ap_med.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-ap-med\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv task2_aw_avg\n",
    "task2_aw_avg.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-aw-avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export csv task2_aw_med\n",
    "task2_aw_med.limit(100).coalesce(1)\\\n",
    "       .write.csv(\"task2-aw-med\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
